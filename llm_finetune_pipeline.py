import os
import torch
import wandb
import yaml
import numpy as np
import pandas as pd
import sklearn.metrics as metrics
from tqdm import tqdm
from transformers import (
    AutoModel,
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    DataCollatorWithPadding
)
from peft import (
    get_peft_model,
    get_peft_model_state_dict,
    LoraConfig,
    IA3Config,
    AdaLoraConfig,
    TaskType,
    PeftType
)
from datasets import load_dataset, Dataset, DatasetDict
import optuna

# ==============================================================================
#  ConfigParserç±»ç”¨äºè§£æYAMLé…ç½®æ–‡ä»¶
# ==============================================================================
class ConfigParser:
    def __init__(self, config_file):
        """
        åˆå§‹åŒ–é…ç½®è§£æå™¨
        
        Args:
            config_file (str): YAMLé…ç½®æ–‡ä»¶çš„è·¯å¾„
        """
        self.config_file = config_file
        self.config = self._load_config()
        
    def _load_config(self):
        """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
        if not os.path.exists(self.config_file):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨")
            
        with open(self.config_file, 'r') as f:
            config = yaml.safe_load(f)# yaml.safe_load()è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œè¯¥å­—å…¸åŒ…å«é…ç½®æ–‡ä»¶ä¸­çš„æ‰€æœ‰é”®å€¼å¯¹
        return config
    
    def get_experiment_config(self):
        """è·å–å®éªŒåŸºæœ¬é…ç½®"""
        exp_config = self.config.get('experiment')
        return {
            'model_name': exp_config.get('model_name'),
            'dataset_name': exp_config.get('dataset_name'),
            'task_type': exp_config.get('task_type')
        }
    
    def get_peft_config(self):
        """è·å–PEFTæ–¹æ³•å’Œå‚æ•°é…ç½®"""
        peft_config = self.config.get('peft')
        return {
            'method': peft_config.get('method'),
            'params': peft_config.get('params')
        }
    
    def get_training_config(self):
        """è·å–è®­ç»ƒå‚æ•°é…ç½®"""
        return self.config.get('training')
    
    def get_tuner_config(self):
        """è·å–è¶…å‚æ•°ä¼˜åŒ–å™¨é…ç½®"""
        tuner_config = self.config.get('tuner')
        return {
            'direction': tuner_config.get('direction'),
            'n_trials': tuner_config.get('n_trials'),
            'study_name': tuner_config.get('study_name')
        }
    
    def get_peft_search_space(self):
        """è·å–PEFTæ–¹æ³•çš„æœç´¢ç©ºé—´é…ç½®"""
        return self.config.get('search_space').get('peft')
    
    def get_training_search_space(self):
        """è·å–è®­ç»ƒå‚æ•°çš„æœç´¢ç©ºé—´é…ç½®"""
        return self.config.get('search_space').get('training')

# ==============================================================================
#  PEFTExperimentç±»ç”¨äºæ‰§è¡ŒPEFTè®­ç»ƒå’Œè¯„ä¼°
# ==============================================================================
class PEFTExperiment:
    def __init__(self, model_name, dataset_name, task_type):
        self.model_name = model_name
        self.dataset_name = dataset_name
        self.task_type = task_type
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
            print("pad_token is None, set to eos_token")
    
    def get_peft_config(self, method, **kwargs):
        """è·å–ä¸åŒPEFTæ–¹æ³•çš„é…ç½®"""
        configs = {
            "lora": LoraConfig(
                task_type=self.task_type,
                inference_mode=False,
                r=kwargs.get("r"),
                lora_alpha=kwargs.get("lora_alpha"),# å†³å®šdelta_Wçš„å½±å“
                lora_dropout=kwargs.get("lora_dropout"),
                target_modules=kwargs.get("target_modules")
            ),
            "ia3": IA3Config(
                task_type=self.task_type,
                inference_mode=False,
                target_modules=kwargs.get("target_modules"),
                feedforward_modules=kwargs.get("feedforward_modules")
            ),
            "adalora": AdaLoraConfig(
                task_type=self.task_type,
                inference_mode=False,
                r=kwargs.get("r"),
                lora_alpha=kwargs.get("lora_alpha"),
                target_r=kwargs.get("target_r"),
                init_r=kwargs.get("init_r"),
                tinit=kwargs.get("tinit"),
                tfinal=kwargs.get("tfinal"),
                deltaT=kwargs.get("deltaT"),
                lora_dropout=kwargs.get("lora_dropout"),
                target_modules=kwargs.get("target_modules")
            )
        }
        return configs[method.lower()]
    
    def prepare_data(self):
        """å‡†å¤‡æ•°æ®é›†ï¼Œä»parsed_genome.csvæ–‡ä»¶åŠ è½½"""
        # ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®
        df = pd.read_csv('parsed_genome.csv')
        
        # å°†æ•°æ®è½¬æ¢ä¸ºHugging Face Datasetæ ¼å¼
        # ä½¿ç”¨'contig'åˆ—ä½œä¸ºæ–‡æœ¬è¾“å…¥ï¼Œ'organism_name'åˆ—ä½œä¸ºæ ‡ç­¾
        train_df = df.sample(frac=0.8, random_state=42)
        val_df = df.drop(train_df.index)
        
        # åˆ›å»ºæ ‡ç­¾åˆ°IDçš„æ˜ å°„
        unique_labels = df['organism_name'].unique().tolist()
        label_to_id = {label: i for i, label in enumerate(unique_labels)}
        
        # æ·»åŠ æ ‡ç­¾IDåˆ—
        train_df['label'] = train_df['organism_name'].map(label_to_id)
        val_df['label'] = val_df['organism_name'].map(label_to_id)
        
        dataset_dict = {
            'train': Dataset.from_pandas(train_df),
            'validation': Dataset.from_pandas(val_df)
        }
        
        # åˆ›å»ºä¸€ä¸ªDatasetå¯¹è±¡
        dataset = DatasetDict(dataset_dict)
        
        def tokenize_function(examples):
            # ä½¿ç”¨'contig'åˆ—ä½œä¸ºæ–‡æœ¬è¾“å…¥ï¼Œä¸ä½¿ç”¨æˆªæ–­å’Œå¡«å……
            return self.tokenizer(
                examples["contig"],
                truncation=False,
                padding=False
            )
        
        tokenized_dataset = dataset.map(tokenize_function, batched=True)
        
        # ä¿å­˜æ ‡ç­¾æ˜ å°„ä¿¡æ¯ï¼Œæ–¹ä¾¿åç»­é¢„æµ‹æ—¶ä½¿ç”¨
        self.label_to_id = label_to_id
        self.id_to_label = {i: label for label, i in label_to_id.items()}
        
        return tokenized_dataset
    
    def train_with_peft(self, peft_method, peft_params, training_params):
        """ä½¿ç”¨PEFTæ–¹æ³•è®­ç»ƒæ¨¡å‹"""

        # åˆå§‹åŒ–wandb
        run = wandb.init(
            project="fungi_LLM_finetune",
            name=f"{peft_method}_{self.model_name}_{self.dataset_name}_{run.id}",
            config={
                "model": self.model_name,
                "peft_method": peft_method,
                "peft_params": peft_params,#å‚æ•°é«˜æ•ˆå¾®è°ƒè¶…å‚æ•°
                **training_params#è®­ç»ƒè¶…å‚æ•°
            }
        )
        
        # å‡†å¤‡æ•°æ®
        dataset = self.prepare_data()# è¿”å›tokenized_dataset
        
        # è·å–æ ‡ç­¾æ•°é‡
        num_labels = len(self.label_to_id)
        print(f"åˆ†ç±»ä»»åŠ¡æ ‡ç­¾æ•°é‡: {num_labels}")
        print(f"æ ‡ç­¾æ˜ å°„: {self.label_to_id}")
        
        # åŠ è½½æ¨¡å‹
        model = AutoModelForSequenceClassification.from_pretrained(
            self.model_name,
            num_labels=num_labels  # æ ¹æ®organism_nameçš„å”¯ä¸€å€¼æ•°é‡è®¾ç½®
        )   
        # åº”ç”¨PEFTé…ç½®
        peft_config = self.get_peft_config(peft_method, **peft_params)
        model = get_peft_model(model, peft_config)#åº”ç”¨é…ç½®åçš„PEFTæ¨¡å‹
        
        # è‡ªå®šä¹‰æ•°æ®æ•´ç†å™¨ï¼Œä½¿ç”¨åŸå§‹tokenåºåˆ—ï¼Œä¸è¿›è¡Œå¡«å……
        def custom_data_collator(features):
            # åªå°†input_idså’Œlabelsæ”¶é›†åˆ°ä¸€èµ·ï¼Œä¸è¿›è¡Œå¡«å……æ“ä½œ
            batch = {}
            batch["input_ids"] = [feature["input_ids"] for feature in features]
            batch["attention_mask"] = [feature["attention_mask"] for feature in features]
            batch["labels"] = torch.tensor([feature["label"] for feature in features])
            return batch
        
        # è®­ç»ƒå‚æ•°
        training_args = TrainingArguments(
            output_dir=f"./llm_fne_tune_results/{peft_method}_{self.model_name}_{self.dataset_name}_{run.id}",

            learning_rate=training_params.get("learning_rate"),
            per_device_train_batch_size=1,  # è®¾ç½®ä¸º1ä»¥é¿å…æ‰¹å¤„ç†é—®é¢˜
            num_train_epochs=training_params.get("epochs"),
            #weight_decay=training_params.get("weight_decay"),

            logging_steps=100,
            evaluation_strategy="epoch",# å®šä¹‰evaluationæ—¶æœº
            save_strategy="epoch",# å®šä¹‰æ¨¡å‹ä¿å­˜æ—¶æœº
            load_best_model_at_end=True,# ç¡®ä¿è®­ç»ƒç»“æŸæ—¶åŠ è½½è¡¨ç°æœ€ä½³çš„æ¨¡å‹
            metric_for_best_model="eval_loss",# è¯„åˆ¤ä¿å­˜çš„æ ‡å‡†
            save_total_limit=1,# æ¯å½“æ–°æ£€æŸ¥ç‚¹ä¿å­˜æ—¶ä¼šåˆ é™¤æ—§æ£€æŸ¥ç‚¹
            
            report_to="wandb",
            disable_tqdm=False  # ç¡®ä¿ä¸ç¦ç”¨tqdmè¿›åº¦æ¡
        )
        
        # Define a compute_metrics function to calculate and log metrics during training
        def compute_metrics(eval_pred):
            logits, labels = eval_pred
            predictions = np.argmax(logits, axis=-1)
            
            # å¤šåˆ†ç±»è¯„ä¼°
            accuracy = metrics.accuracy_score(labels, predictions)
            f1_macro = metrics.f1_score(labels, predictions, average='macro')
            f1_weighted = metrics.f1_score(labels, predictions, average='weighted')
            
            return {
                'accuracy': accuracy,
                'f1_macro': f1_macro,
                'f1_weighted': f1_weighted
            }

        # Initialize the Trainer with compute_metrics
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=dataset["train"],
            eval_dataset=dataset["validation"] if "validation" in dataset else dataset["test"],
            tokenizer=self.tokenizer,
            data_collator=custom_data_collator,  # ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®æ•´ç†å™¨
            compute_metrics=compute_metrics# metrics for evaluation
        )

        # Train the model
        import time
        start_time = time.time()
        
        # ä½¿ç”¨tqdmæ˜¾ç¤ºè®­ç»ƒè¿›åº¦
        print("\nå¼€å§‹è®­ç»ƒæ¨¡å‹...")
        total_steps = int(len(dataset["train"]) / training_args.per_device_train_batch_size * training_args.num_train_epochs)
        with tqdm(total=total_steps, desc="è®­ç»ƒè¿›åº¦") as pbar:
            # åˆ›å»ºä¸€ä¸ªå›è°ƒå‡½æ•°æ¥æ›´æ–°è¿›åº¦æ¡
            class TqdmCallback:
                def __init__(self, pbar):
                    self.pbar = pbar
                
                def on_log(self, args, state, control, logs=None, **kwargs):
                    if state.is_local_process_zero and logs:
                        _ = logs.pop("total_flos", None)
                        if state.global_step > 0:
                            self.pbar.update(1)
            
            # æ·»åŠ å›è°ƒå‡½æ•°åˆ°trainer
            trainer.add_callback(TqdmCallback(pbar))
            trainer.train()
        
        training_time = time.time() - start_time

        # Log the training time and number of trainable parameters
        wandb.log({
            "trainable_params": model.get_nb_trainable_parameters(),
            "training_time": training_time,
            "num_labels": num_labels
        })

        wandb.finish()
        
        return {}


# ==============================================================================
#  å®šä¹‰é¢å‘å¯¹è±¡çš„ HyperparameterTuner ç±»
# ==============================================================================
class HyperparameterTuner:
    """
    ä¸€ä¸ªä½¿ç”¨ Optuna è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–çš„å°è£…ç±»ã€‚
    
    è¿™ä¸ªç±»å°†è¶…å‚æ•°æœç´¢ç©ºé—´å®šä¹‰ã€Optuna studyç®¡ç†å’Œä¼˜åŒ–æ‰§è¡Œè¿‡ç¨‹
    """
    
    def __init__(self, experiment, direction="minimize", study_name=None, search_space=None):
        """
        æ„é€ å‡½æ•°ã€‚
        
        Args:
            experiment: å®ç°äº† .train_with_peft(...) æ–¹æ³•çš„å®éªŒå¯¹è±¡ã€‚
            direction (str): ä¼˜åŒ–çš„æ–¹å‘ï¼Œ"minimize" æˆ– "maximize"ã€‚
            study_name (str, optional): Optuna study çš„åç§°ï¼Œç”¨äºæŒä¹…åŒ–ã€‚
            search_space (dict, optional): è¶…å‚æ•°æœç´¢ç©ºé—´é…ç½®ã€‚
        """
        self.experiment = experiment
        self.direction = direction
        self.study_name = study_name
        self.search_space = search_space or {}
        
        # åœ¨æ„é€ å‡½æ•°ä¸­åˆ›å»º study å¯¹è±¡ï¼Œç®¡ç†æ•´ä¸ªä¼˜åŒ–è¿‡ç¨‹çš„çŠ¶æ€
        self.study = optuna.create_study(direction=self.direction, study_name=self.study_name)

    def _objective(self, trial):
        """
        é€‰æ‹©å‚æ•°ã€è®­ç»ƒæ¨¡å‹ã€è¿”å›ç»“æœ
        
        Args:
            trial (optuna.trial.Trial): Optuna çš„ trial å¯¹è±¡ï¼Œç”¨äºå»ºè®®å‚æ•°ã€‚
            
        Returns:
            float: éœ€è¦è¢«ä¼˜åŒ–çš„è¯„ä¼°æŒ‡æ ‡ï¼ˆä¾‹å¦‚ï¼ŒéªŒè¯é›†æŸå¤±ï¼‰ã€‚
        """
        # 1. è·å–PEFTæ–¹æ³•æœç´¢ç©ºé—´
        peft_space = self.search_space.get('peft')
        peft_methods = peft_space.get('methods')
        
        # é€‰æ‹©PEFTæ–¹æ³•
        peft_method = trial.suggest_categorical("peft_method", peft_methods)
        
        # 2. æ ¹æ®æ–¹æ³•é€‰æ‹©æ¡ä»¶ä¾èµ–çš„å‚æ•°
        peft_params = {}
        if peft_method == "lora":
            lora_space = peft_space.get('lora')
            peft_params = {
                "r": trial.suggest_int("r", 
                                      lora_space.get('r', {}).get('min'), 
                                      lora_space.get('r', {}).get('max'), 
                                      step=lora_space.get('r', {}).get('step')),
                "lora_alpha": trial.suggest_int("lora_alpha", 
                                               lora_space.get('lora_alpha', {}).get('min'), 
                                               lora_space.get('lora_alpha', {}).get('max'), 
                                               step=lora_space.get('lora_alpha', {}).get('step')),
                "lora_dropout": trial.suggest_float("lora_dropout", 
                                                   lora_space.get('lora_dropout', {}).get('min'), 
                                                   lora_space.get('lora_dropout', {}).get('max'))
            }
        elif peft_method == "ia3":
            # IA3 æ²¡æœ‰é¢å¤–å‚æ•°
            peft_params = {}
        else:  # adalora
            adalora_space = peft_space.get('adalora', {})
            peft_params = {
                "r": trial.suggest_int("r", 
                                      adalora_space.get('r', {}).get('min'), 
                                      adalora_space.get('r', {}).get('max'), 
                                      step=adalora_space.get('r', {}).get('step')),
                "target_r": trial.suggest_int("target_r", 
                                             adalora_space.get('target_r', {}).get('min'), 
                                             adalora_space.get('target_r', {}).get('max'), 
                                             step=adalora_space.get('target_r', {}).get('step')),
                "lora_alpha": trial.suggest_int("lora_alpha", 
                                               adalora_space.get('lora_alpha', {}).get('min'), 
                                               adalora_space.get('lora_alpha', {}).get('max'), 
                                               step=adalora_space.get('lora_alpha', {}).get('step'))
            }
            
        # 3. è·å–è®­ç»ƒå‚æ•°æœç´¢ç©ºé—´
        training_space = self.search_space.get('training', {})
        
        # å®šä¹‰é€šç”¨çš„è®­ç»ƒå‚æ•°
        training_params = {
            "learning_rate": trial.suggest_float("learning_rate", 
                                               training_space.get('learning_rate', {}).get('min'), 
                                               training_space.get('learning_rate', {}).get('max'), 
                                               log=training_space.get('learning_rate', {}).get('log')),
            "batch_size": trial.suggest_categorical("batch_size", 
                                                  training_space.get('batch_size', {}).get('values')),
            "epochs": trial.suggest_int("epochs", 
                                       training_space.get('epochs', {}).get('min'), 
                                       training_space.get('epochs', {}).get('max')),
            "weight_decay": trial.suggest_float("weight_decay", 
                                              training_space.get('weight_decay', {}).get('min'), 
                                              training_space.get('weight_decay', {}).get('max'), 
                                              log=training_space.get('weight_decay', {}).get('log'))
        }
        
        # 4. ä½¿ç”¨ self.experiment è°ƒç”¨è®­ç»ƒå’Œè¯„ä¼°
        results = self.experiment.train_with_peft(peft_method, peft_params, training_params)
        
        # 5. è¿”å›ä¼˜åŒ–çš„ç›®æ ‡å€¼
        return results["eval_loss"]

    def run(self, n_trials):
        """
        å¯åŠ¨è¶…å‚æ•°ä¼˜åŒ–è¿‡ç¨‹ã€‚
        
        Args:
            n_trials (int): è¦è¿è¡Œçš„æ€»è¯•éªŒæ¬¡æ•°ã€‚
        """
        # å°†ç±»æ–¹æ³• _objective ä½œä¸ºä¼˜åŒ–ç›®æ ‡ä¼ å…¥
        self.study.optimize(self._objective, n_trials=n_trials)# callback _objective -> Trail injection -> trial_suggest_*:sampler call -> suggested_parameters -> train -> return eval_loss
        
        print("\nğŸ‰ğŸ‰ğŸ‰ ä¼˜åŒ–å®Œæˆ! ğŸ‰ğŸ‰ğŸ‰")

    def summarize_results(self):
        """æ‰“å°æœ€æœ‰ç›®æ ‡å€¼åŠå¯¹åº”è¶…å‚æ•°ç»„åˆ"""
        if self.study.best_trial:
            print(f"\nğŸ“Š æœ€ä½³ç»“æœ:")
            print(f"  - ç›®æ ‡å€¼ (eval_loss): {self.study.best_value:.4f}")
            print("  - æœ€ä½³å‚æ•°ç»„åˆ:")
            for key, value in self.study.best_params.items():
                print(f"    - {key}: {value}")
        else:
            print("å°šæœªè¿›è¡Œä»»ä½•è¯•éªŒã€‚")


if __name__ == "__main__":
    import argparse
    
    # å‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="PEFTæ¨¡å‹å¾®è°ƒè„šæœ¬")
    parser.add_argument('--config', type=str, required=True, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--mode', type=str, default='train', choices=['train', 'tune'], help='æ‰§è¡Œæ¨¡å¼: trainæˆ–tune')
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    config_parser = ConfigParser(args.config)
    
    # è·å–å®éªŒé…ç½®
    exp_config = config_parser.get_experiment_config()
    
    # åˆå§‹åŒ–å®éªŒ
    My_experiment = PEFTExperiment(
        model_name=exp_config['model_name'],
        dataset_name=exp_config['dataset_name'],
        task_type=exp_config['task_type']
    )
    
    if args.mode == 'train':
        # è·å–PEFTå’Œè®­ç»ƒé…ç½®
        peft_config = config_parser.get_peft_config()#.yamlæ–‡ä»¶ä¸­çš„pefté…ç½®
        training_config = config_parser.get_training_config()#.yamlæ–‡ä»¶ä¸­çš„trainingé…ç½®
        
        # æ‰§è¡Œå•æ¬¡è®­ç»ƒ
        results = My_experiment.train_with_peft(
            peft_method=peft_config['method'],
            peft_params=peft_config['params'],
            training_params=training_config
        )
        print(f"è®­ç»ƒå®Œæˆâœ…")
        
    else:  # tuneæ¨¡å¼
        # è·å–è¶…å‚æ•°ä¼˜åŒ–å™¨é…ç½®
        tuner_config = config_parser.get_tuner_config()
        
        # è·å–æœç´¢ç©ºé—´
        search_space = {
            'peft': config_parser.get_peft_search_space(),
            'training': config_parser.get_training_search_space()
        }
        
        # æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–
        tuner = HyperparameterTuner(
            experiment=My_experiment,
            direction=tuner_config['direction'],
            study_name=tuner_config['study_name'],
            search_space=search_space
        )
        tuner.run(n_trials=tuner_config['n_trials'])
        tuner.summarize_results()