import os
import torch
import yaml
import numpy as np
import pandas as pd
import sklearn.metrics as metrics
from tqdm import tqdm
from transformers import (
    AutoModel,
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    DataCollatorWithPadding
)
from peft import (
    get_peft_model,
    get_peft_model_state_dict,
    LoraConfig,
    IA3Config,
    AdaLoraConfig,
    TaskType,
    PeftType
)
from datasets import load_dataset, Dataset, DatasetDict
import optuna
import pickle
import gc
import time

# è¾…åŠ©å‡½æ•°ï¼Œç”¨äºä¿å­˜CUDAå†…å­˜å¿«ç…§
def save_memory_snapshot(filename=None):
    """ä¿å­˜CUDAå†…å­˜å¿«ç…§åˆ°æ–‡ä»¶ä¸­"""
    if not torch.cuda.is_available():
        print("CUDAä¸å¯ç”¨ï¼Œæ— æ³•ä¿å­˜å†…å­˜å¿«ç…§")
        return
        
    filename = filename or f"memory_snapshot_{time.strftime('%Y%m%d_%H%M%S')}.pickle"
    snapshot = torch.cuda.memory._snapshot()
    with open(filename, 'wb') as f:
        pickle.dump(snapshot, f)
    print(f"å†…å­˜å¿«ç…§å·²ä¿å­˜è‡³ {filename}")
    print("\n--- å†…å­˜å¿«ç…§æ‘˜è¦ ---")
    print(torch.cuda.memory_summary())
    print("---------------------------\n")
    print(f"æ‚¨å¯ä»¥åœ¨ https://pytorch.org/memory_viz ä¸ŠæŸ¥çœ‹å†…å­˜å¿«ç…§è¯¦æƒ…")

# ==============================================================================
#  ConfigParserç±»ç”¨äºè§£æYAMLé…ç½®æ–‡ä»¶
# ==============================================================================
class ConfigParser:
    def __init__(self, config_file):
        """
        åˆå§‹åŒ–é…ç½®è§£æå™¨
        
        Args:
            config_file (str): YAMLé…ç½®æ–‡ä»¶çš„è·¯å¾„
        """
        self.config_file = config_file
        self.config = self._load_config()
        
    def _load_config(self):
        """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
        if not os.path.exists(self.config_file):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨")
            
        with open(self.config_file, 'r') as f:
            config = yaml.safe_load(f)# yaml.safe_load()è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œè¯¥å­—å…¸åŒ…å«é…ç½®æ–‡ä»¶ä¸­çš„æ‰€æœ‰é”®å€¼å¯¹
        return config
    
    def get_experiment_config(self):
        """è·å–å®éªŒåŸºæœ¬é…ç½®"""
        exp_config = self.config.get('experiment')
        return {
            'model_name': exp_config.get('model_name'),
            'dataset_name': exp_config.get('dataset_name'),
            'task_type': exp_config.get('task_type')
        }
    
    def get_peft_config(self):
        """è·å–PEFTæ–¹æ³•å’Œå‚æ•°é…ç½®"""
        peft_config = self.config.get('peft')
        return {
            'method': peft_config.get('method'),
            'params': peft_config.get('params')
        }
    
    def get_training_config(self):
        """è·å–è®­ç»ƒå‚æ•°é…ç½®"""
        return self.config.get('training')
    
    def get_tuner_config(self):
        """è·å–è¶…å‚æ•°ä¼˜åŒ–å™¨é…ç½®"""
        tuner_config = self.config.get('tuner')
        return {
            'direction': tuner_config.get('direction'),
            'n_trials': tuner_config.get('n_trials'),
            'study_name': tuner_config.get('study_name')
        }
    
    def get_peft_search_space(self):
        """è·å–PEFTæ–¹æ³•çš„æœç´¢ç©ºé—´é…ç½®"""
        return self.config.get('search_space').get('peft')
    
    def get_training_search_space(self):
        """è·å–è®­ç»ƒå‚æ•°çš„æœç´¢ç©ºé—´é…ç½®"""
        return self.config.get('search_space').get('training')

# ==============================================================================
#  PEFTExperimentç±»ç”¨äºæ‰§è¡ŒPEFTè®­ç»ƒå’Œè¯„ä¼°
# ==============================================================================
class PEFTExperiment:
    def __init__(self, model_name, dataset_name, task_type, config):
        self.model_name = model_name
        self.dataset_name = dataset_name
        self.task_type = task_type
        self.config = config
        # ä»æœ¬åœ°ç›®å½•åŠ è½½tokenizer
        print(f"ä»æœ¬åœ°ç›®å½•åŠ è½½tokenizer: {model_name}")
        self.tokenizer = AutoTokenizer.from_pretrained(model_name, local_files_only=True)
        
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
            print("pad_token is None, set to eos_token")
    
    def get_peft_config(self, method, **kwargs):
        """è·å–ä¸åŒPEFTæ–¹æ³•çš„é…ç½®"""
        configs = {
            "lora": LoraConfig(
                task_type=self.task_type,
                inference_mode=False,
                r=kwargs.get("r"),
                lora_alpha=kwargs.get("lora_alpha"),# å†³å®šdelta_Wçš„å½±å“
                lora_dropout=kwargs.get("lora_dropout"),
                target_modules=kwargs.get("target_modules")
            ),
            "ia3": IA3Config(
                task_type=self.task_type,
                inference_mode=False,
                target_modules=kwargs.get("target_modules"),
                feedforward_modules=kwargs.get("feedforward_modules")
            )
        }
        return configs[method.lower()]
    
    def prepare_data(self):
        """å‡†å¤‡æ•°æ®é›†ï¼Œä»parsed_genome.csvæ–‡ä»¶åŠ è½½"""
        print("å¼€å§‹å‡†å¤‡æ•°æ®...")
        # ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®
        df = pd.read_csv('parsed_genome.csv')
        
        # è®¡ç®—å¹¶è®°å½•åºåˆ—é•¿åº¦ä¿¡æ¯
        if 'contig' in df.columns:
            df['sequence_length'] = df['contig'].str.len()
            max_length = df['sequence_length'].max()
            avg_length = df['sequence_length'].mean()
            print(f"æ•°æ®é›†åºåˆ—é•¿åº¦ç»Ÿè®¡: æœ€å¤§é•¿åº¦={max_length}, å¹³å‡é•¿åº¦={avg_length}")
            
            # è®°å½•åºåˆ—é•¿åº¦åˆ†å¸ƒ
            length_bins = [0, 512, 1024, 2048, 4096, 8192, 16384, float('inf')]
            length_counts = [((df['sequence_length'] > length_bins[i]) & (df['sequence_length'] <= length_bins[i+1])).sum() 
                            for i in range(len(length_bins)-1)]
            length_labels = [f"{length_bins[i]}-{length_bins[i+1]}" for i in range(len(length_bins)-1)]
            
            print("åºåˆ—é•¿åº¦åˆ†å¸ƒ:")
            for label, count in zip(length_labels, length_counts):
                print(f"  {label}: {count} æ¡åºåˆ—")
                
            # æ‰¾å‡ºæœ€é•¿çš„åºåˆ—å¹¶è®°å½•å…¶IDå’Œé•¿åº¦
            longest_seq_idx = df['sequence_length'].idxmax()
            print(f"æœ€é•¿åºåˆ—ID: {longest_seq_idx}, é•¿åº¦: {df.loc[longest_seq_idx, 'sequence_length']}")
        
        # å°†æ•°æ®è½¬æ¢ä¸ºHugging Face Datasetæ ¼å¼
        # ä½¿ç”¨'contig'åˆ—ä½œä¸ºæ–‡æœ¬è¾“å…¥ï¼Œ'organism_name'åˆ—ä½œä¸ºæ ‡ç­¾
        train_df = df.sample(frac=0.8, random_state=42)
        val_df = df.drop(train_df.index)
        
        # åˆ›å»ºæ ‡ç­¾åˆ°IDçš„æ˜ å°„
        unique_labels = df['organism_name'].unique().tolist()
        label_to_id = {label: i for i, label in enumerate(unique_labels)}
        
        # æ·»åŠ æ ‡ç­¾IDåˆ—
        train_df['label'] = train_df['organism_name'].map(label_to_id)
        val_df['label'] = val_df['organism_name'].map(label_to_id)
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"æ ‡ç­¾ç±»å‹: {train_df['label'].dtype}")
        print(f"æ ‡ç­¾ç¤ºä¾‹: {train_df['label'].iloc[:5].tolist()}")
        
        dataset_dict = {
            'train': Dataset.from_pandas(train_df),
            'validation': Dataset.from_pandas(val_df)
        }
        
        # åˆ›å»ºä¸€ä¸ªDatasetå¯¹è±¡
        dataset = DatasetDict(dataset_dict)
        
        # ä½¿ç”¨profileråˆ†ætokenizeè¿‡ç¨‹
        def tokenize_function(examples):
            # ä½¿ç”¨è¾ƒå°çš„max_lengthæ¥é¿å…OOM
            max_length = 512  # é™ä½æ­¤å€¼ä»¥å‡å°‘å†…å­˜ä½¿ç”¨ï¼Œå¯ä»¥æ ¹æ®æ‚¨çš„æ•°æ®é›†å’ŒGPUå†…å­˜è°ƒæ•´
            
            # ä½¿ç”¨'contig'åˆ—ä½œä¸ºæ–‡æœ¬è¾“å…¥ï¼Œå¯ç”¨æˆªæ–­å’Œå¡«å……ä»¥é˜²æ­¢OOM
            result = self.tokenizer(
                examples["contig"],
                truncation=True,
                padding="max_length",
                max_length=max_length
            )
            
            # ç¡®ä¿æ ‡ç­¾å­—æ®µåç§°æ­£ç¡®
            if "label" in examples:
                result["labels"] = examples["label"]  # ä¿æŒæ ‡ç­¾ä¸ºæ•´å‹
            return result
        
        print("å¼€å§‹tokenizeæ•°æ®...")
        # è®°å½•tokenizeå‰çš„å†…å­˜
        if torch.cuda.is_available():
            before_mem = torch.cuda.memory_allocated() / (1024 * 1024)
            print(f"Tokenizeå‰å†…å­˜ä½¿ç”¨: {before_mem:.2f} MB")

        # æ‰§è¡Œtokenizeæ“ä½œ
        tokenized_dataset = dataset.map(tokenize_function, batched=True, batch_size=32)
        
        # è®°å½•tokenizeåçš„å†…å­˜
        if torch.cuda.is_available():
            after_mem = torch.cuda.memory_allocated() / (1024 * 1024)
            print(f"Tokenizeåå†…å­˜ä½¿ç”¨: {after_mem:.2f} MB")
            print(f"Tokenizeè¿‡ç¨‹å†…å­˜å¢åŠ : {after_mem - before_mem:.2f} MB")
        
        # æ‰“å°å¤„ç†åçš„æ•°æ®é›†ä¿¡æ¯
        print(f"å¤„ç†åçš„æ•°æ®é›†ç»“æ„: {tokenized_dataset}")
        
        # ä¿å­˜æ ‡ç­¾æ˜ å°„ä¿¡æ¯ï¼Œæ–¹ä¾¿åç»­é¢„æµ‹æ—¶ä½¿ç”¨
        self.label_to_id = label_to_id
        self.id_to_label = {i: label for label, i in label_to_id.items()}
        
        return tokenized_dataset
    
    def train_with_peft(self, peft_method, peft_params, training_params):
        """ä½¿ç”¨PEFTæ–¹æ³•è®­ç»ƒæ¨¡å‹"""
        # ä¸ºTensorBoardåˆ›å»ºæ—¥å¿—ç›®å½•
        log_dir = f"./tensorboard_logs/{peft_method}_{self.model_name.split('/')[-1]}_{self.dataset_name}"
        os.makedirs(log_dir, exist_ok=True)
        
        # å‡†å¤‡æ•°æ®
        print("å¼€å§‹æ•°æ®å‡†å¤‡é˜¶æ®µ...")
        dataset = self.prepare_data()
        
        # è·å–æ ‡ç­¾æ•°é‡
        num_labels = len(self.label_to_id)
        print(f"åˆ†ç±»ä»»åŠ¡æ ‡ç­¾æ•°é‡: {num_labels}")
        print(f"æ ‡ç­¾æ˜ å°„: {self.label_to_id}")
        
        print("å¼€å§‹åŠ è½½æ¨¡å‹...")
        # è®°å½•æ¨¡å‹åŠ è½½å‰çš„å†…å­˜
        if torch.cuda.is_available():
            before_mem = torch.cuda.memory_allocated() / (1024 * 1024)
            print(f"æ¨¡å‹åŠ è½½å‰å†…å­˜ä½¿ç”¨: {before_mem:.2f} MB")
            
        # ä»æœ¬åœ°ç›®å½•åŠ è½½æ¨¡å‹
        model = AutoModelForSequenceClassification.from_pretrained(
            self.model_name,
            num_labels=num_labels,
            problem_type="single_label_classification",
            local_files_only=True,
            trust_remote_code=True
        )
        
        # è®°å½•æ¨¡å‹åŠ è½½åçš„å†…å­˜
        if torch.cuda.is_available():
            after_mem = torch.cuda.memory_allocated() / (1024 * 1024)
            print(f"æ¨¡å‹åŠ è½½åå†…å­˜ä½¿ç”¨: {after_mem:.2f} MB")
            print(f"æ¨¡å‹åŠ è½½å†…å­˜å¢åŠ : {after_mem - before_mem:.2f} MB")
        
        # åº”ç”¨PEFTé…ç½®
        print("åº”ç”¨PEFTé…ç½®...")
        if torch.cuda.is_available():
            before_mem = torch.cuda.memory_allocated() / (1024 * 1024)
            print(f"PEFTåº”ç”¨å‰å†…å­˜ä½¿ç”¨: {before_mem:.2f} MB")
            
        peft_config = self.get_peft_config(peft_method, **peft_params)
        model = get_peft_model(model, peft_config)
        
        # è®°å½•PEFTåº”ç”¨åçš„å†…å­˜
        if torch.cuda.is_available():
            after_mem = torch.cuda.memory_allocated() / (1024 * 1024)
            print(f"PEFTåº”ç”¨åå†…å­˜ä½¿ç”¨: {after_mem:.2f} MB")
            print(f"PEFTåº”ç”¨å†…å­˜å¢åŠ : {after_mem - before_mem:.2f} MB")
        
        # æ‰“å°æ¨¡å‹å‚æ•°æƒ…å†µ
        model.print_trainable_parameters()
        
        # ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®æ•´ç†å™¨
        data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)
        
        # è®­ç»ƒå‚æ•°
        run_name = f"{peft_method}_{self.model_name}_{self.dataset_name}"
        training_args = TrainingArguments(
            output_dir=f"./llm_fne_tune_results/{run_name}",
            learning_rate=float(training_params.get("learning_rate")),  # è½¬æ¢ä¸ºæµ®ç‚¹æ•°
            per_device_train_batch_size=1,  # è®¾ç½®ä¸º1ä»¥é¿å…æ‰¹å¤„ç†é—®é¢˜
            num_train_epochs=float(training_params.get("epochs")),  # è½¬æ¢ä¸ºæµ®ç‚¹æ•°
            logging_steps=100,
            save_total_limit=1,
            report_to="tensorboard",
            logging_dir=log_dir,
            disable_tqdm=False
        )
        
        # åˆ›å»ºä¸€ä¸ªæ”¯æŒPyTorch Profilerçš„è‡ªå®šä¹‰Trainerç±»
        class ProfilerTrainer(Trainer):
            def __init__(self, **kwargs):
                super().__init__(**kwargs)
                self.step_counter = 0
                
            def training_step(self, model, inputs, num_items_in_batch):
                """ä½¿ç”¨PyTorch Profileré‡å†™è®­ç»ƒæ­¥éª¤"""
                self.step_counter += 1
                
                # æ¯100æ­¥è®°å½•ä¸€æ¬¡å†…å­˜ä½¿ç”¨æƒ…å†µ
                if self.step_counter % 100 == 1:
                    # è®°å½•å½“å‰çš„å†…å­˜ä½¿ç”¨æƒ…å†µè€Œä¸æ˜¯ä½¿ç”¨profiler
                    if torch.cuda.is_available():
                        allocated = torch.cuda.memory_allocated() / (1024 * 1024)
                        reserved = torch.cuda.memory_reserved() / (1024 * 1024)
                        max_mem = torch.cuda.max_memory_allocated() / (1024 * 1024)
                        print(f"\n--- ç¬¬{self.step_counter}æ­¥è®­ç»ƒå†…å­˜ä½¿ç”¨ ---")
                        print(f"å·²åˆ†é…å†…å­˜: {allocated:.2f} MB")
                        print(f"å·²é¢„ç•™å†…å­˜: {reserved:.2f} MB")
                        print(f"å³°å€¼å†…å­˜ä½¿ç”¨: {max_mem:.2f} MB")
                        
                        # ä¿å­˜å†…å­˜å¿«ç…§
                        save_memory_snapshot(f"step_{self.step_counter}_memory.pickle")
                
                # æ­£å¸¸çš„è®­ç»ƒæ­¥éª¤
                outputs = model(**inputs)
                loss = outputs.loss
                loss.backward()
                return loss.detach()

        # Define a compute_metrics function to calculate and log metrics during training
        def compute_metrics(eval_pred):
            logits, labels = eval_pred
            predictions = np.argmax(logits, axis=-1)
            
            # å¤šåˆ†ç±»è¯„ä¼°
            accuracy = metrics.accuracy_score(labels, predictions)
            f1_macro = metrics.f1_score(labels, predictions, average='macro')
            f1_weighted = metrics.f1_score(labels, predictions, average='weighted')
            
            return {
                'accuracy': accuracy,
                'f1_macro': f1_macro,
                'f1_weighted': f1_weighted
            }

        # Initialize the Trainer with profiler support
        trainer = ProfilerTrainer(
            model=model,
            args=training_args,
            train_dataset=dataset["train"],
            eval_dataset=dataset["validation"],
            compute_metrics=compute_metrics,
            data_collator=data_collator,
        )

        # å¯ç”¨CUDAå†…å­˜å†å²è®°å½•
        if torch.cuda.is_available():
            torch.cuda.memory._record_memory_history(enabled=True)
            print("\n--- è®­ç»ƒå¼€å§‹ï¼Œä¿å­˜å†…å­˜å¿«ç…§ ---")
            save_memory_snapshot("start_memory_snapshot.pickle")
            
        start_time = time.time()

        # å¼€å§‹è®­ç»ƒ
        profiler_enabled = torch.cuda.is_available()
        if profiler_enabled:
            print("å¼€å§‹è®­ç»ƒï¼Œæ¯100æ­¥è®°å½•ä¸€æ¬¡æ€§èƒ½åˆ†æ...")
        
        trainer.train()
        
        # è®­ç»ƒå®Œæˆåç”Ÿæˆå†…å­˜å¿«ç…§
        if torch.cuda.is_available():
            print("\n--- è®­ç»ƒå®Œæˆï¼Œä¿å­˜å†…å­˜å¿«ç…§ ---")
            save_memory_snapshot("final_memory_snapshot.pickle")
            print(f"æœ€å¤§å†…å­˜ä½¿ç”¨: {torch.cuda.max_memory_allocated() / (1024 * 1024):.2f} MB")
        
        training_time = time.time() - start_time
        print(f"è®­ç»ƒå®Œæˆï¼Œæ€»ç”¨æ—¶: {training_time:.2f}ç§’")

        # è®°å½•é¢å¤–çš„æŒ‡æ ‡åˆ°TensorBoard
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        trainer.log({
            "trainable_params": trainable_params,
            "training_time": training_time,
            "num_labels": num_labels
        })
        
        print(f"\nè®­ç»ƒå®Œæˆ! å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹è®­ç»ƒæ—¥å¿—:")
        print(f"tensorboard --logdir={log_dir}")
        
        return {}


# ==============================================================================
#  å®šä¹‰é¢å‘å¯¹è±¡çš„ HyperparameterTuner ç±»
# ==============================================================================
class HyperparameterTuner:
    """
    ä¸€ä¸ªä½¿ç”¨ Optuna è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–çš„å°è£…ç±»ã€‚
    
    è¿™ä¸ªç±»å°†è¶…å‚æ•°æœç´¢ç©ºé—´å®šä¹‰ã€Optuna studyç®¡ç†å’Œä¼˜åŒ–æ‰§è¡Œè¿‡ç¨‹
    """
    
    def __init__(self, experiment, direction="minimize", study_name=None, search_space=None):
        """
        æ„é€ å‡½æ•°ã€‚
        
        Args:
            experiment: å®ç°äº† .train_with_peft(...) æ–¹æ³•çš„å®éªŒå¯¹è±¡ã€‚
            direction (str): ä¼˜åŒ–çš„æ–¹å‘ï¼Œ"minimize" æˆ– "maximize"ã€‚
            study_name (str, optional): Optuna study çš„åç§°ï¼Œç”¨äºæŒä¹…åŒ–ã€‚
            search_space (dict, optional): è¶…å‚æ•°æœç´¢ç©ºé—´é…ç½®ã€‚
        """
        self.experiment = experiment
        self.direction = direction
        self.study_name = study_name
        self.search_space = search_space or {}
        
        # åœ¨æ„é€ å‡½æ•°ä¸­åˆ›å»º study å¯¹è±¡ï¼Œç®¡ç†æ•´ä¸ªä¼˜åŒ–è¿‡ç¨‹çš„çŠ¶æ€
        self.study = optuna.create_study(direction=self.direction, study_name=self.study_name)

    def _objective(self, trial):
        """
        é€‰æ‹©å‚æ•°ã€è®­ç»ƒæ¨¡å‹ã€è¿”å›ç»“æœ
        
        Args:
            trial (optuna.trial.Trial): Optuna çš„ trial å¯¹è±¡ï¼Œç”¨äºå»ºè®®å‚æ•°ã€‚
            
        Returns:
            float: éœ€è¦è¢«ä¼˜åŒ–çš„è¯„ä¼°æŒ‡æ ‡ï¼ˆä¾‹å¦‚ï¼ŒéªŒè¯é›†æŸå¤±ï¼‰ã€‚
        """
        # 1. è·å–PEFTæ–¹æ³•æœç´¢ç©ºé—´
        peft_space = self.search_space.get('peft')
        peft_methods = peft_space.get('methods')
        
        # é€‰æ‹©PEFTæ–¹æ³•
        peft_method = trial.suggest_categorical("peft_method", peft_methods)
        
        # 2. æ ¹æ®æ–¹æ³•é€‰æ‹©æ¡ä»¶ä¾èµ–çš„å‚æ•°
        peft_params = {}
        if peft_method == "lora":
            lora_space = peft_space.get('lora')
            peft_params = {
                "r": trial.suggest_int("r", 
                                      lora_space.get('r', {}).get('min'), 
                                      lora_space.get('r', {}).get('max'), 
                                      step=lora_space.get('r', {}).get('step')),
                "lora_alpha": trial.suggest_int("lora_alpha", 
                                               lora_space.get('lora_alpha', {}).get('min'), 
                                               lora_space.get('lora_alpha', {}).get('max'), 
                                               step=lora_space.get('lora_alpha', {}).get('step')),
                "lora_dropout": trial.suggest_float("lora_dropout", 
                                                   lora_space.get('lora_dropout', {}).get('min'), 
                                                   lora_space.get('lora_dropout', {}).get('max'))
            }
        elif peft_method == "ia3":
            # IA3 æ²¡æœ‰é¢å¤–å‚æ•°
            peft_params = {}
            
        # 3. è·å–è®­ç»ƒå‚æ•°æœç´¢ç©ºé—´
        training_space = self.search_space.get('training', {})
        
        # å®šä¹‰é€šç”¨çš„è®­ç»ƒå‚æ•°
        training_params = {
            "learning_rate": trial.suggest_float("learning_rate", 
                                               training_space.get('learning_rate', {}).get('min'), 
                                               training_space.get('learning_rate', {}).get('max'), 
                                               log=training_space.get('learning_rate', {}).get('log')),
            "batch_size": trial.suggest_categorical("batch_size", 
                                                  training_space.get('batch_size', {}).get('values')),
            "epochs": trial.suggest_int("epochs", 
                                       training_space.get('epochs', {}).get('min'), 
                                       training_space.get('epochs', {}).get('max')),
            "weight_decay": trial.suggest_float("weight_decay", 
                                              training_space.get('weight_decay', {}).get('min'), 
                                              training_space.get('weight_decay', {}).get('max'), 
                                              log=training_space.get('weight_decay', {}).get('log'))
        }
        
        # 4. ä½¿ç”¨ self.experiment è°ƒç”¨è®­ç»ƒå’Œè¯„ä¼°
        results = self.experiment.train_with_peft(peft_method, peft_params, training_params)
        
        # 5. è¿”å›ä¼˜åŒ–çš„ç›®æ ‡å€¼
        return results["eval_loss"]

    def run(self, n_trials):
        """
        å¯åŠ¨è¶…å‚æ•°ä¼˜åŒ–è¿‡ç¨‹ã€‚
        
        Args:
            n_trials (int): è¦è¿è¡Œçš„æ€»è¯•éªŒæ¬¡æ•°ã€‚
        """
        # å°†ç±»æ–¹æ³• _objective ä½œä¸ºä¼˜åŒ–ç›®æ ‡ä¼ å…¥
        self.study.optimize(self._objective, n_trials=n_trials)# callback _objective -> Trail injection -> trial_suggest_*:sampler call -> suggested_parameters -> train -> return eval_loss
        
        print("\nğŸ‰ğŸ‰ğŸ‰ ä¼˜åŒ–å®Œæˆ! ğŸ‰ğŸ‰ğŸ‰")

    def summarize_results(self):
        """æ‰“å°æœ€æœ‰ç›®æ ‡å€¼åŠå¯¹åº”è¶…å‚æ•°ç»„åˆ"""
        if self.study.best_trial:
            print(f"\nğŸ“Š æœ€ä½³ç»“æœ:")
            print(f"  - ç›®æ ‡å€¼ (eval_loss): {self.study.best_value:.4f}")
            print("  - æœ€ä½³å‚æ•°ç»„åˆ:")
            for key, value in self.study.best_params.items():
                print(f"    - {key}: {value}")
        else:
            print("å°šæœªè¿›è¡Œä»»ä½•è¯•éªŒã€‚")

if __name__ == "__main__":
    import argparse
    
    # å‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="PEFTæ¨¡å‹å¾®è°ƒè„šæœ¬")
    parser.add_argument('--config', type=str, required=True, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--mode', type=str, default='train', choices=['train', 'tune'], help='æ‰§è¡Œæ¨¡å¼: trainæˆ–tune')
    parser.add_argument('--max_length', type=int, default=512, help='æœ€å¤§åºåˆ—é•¿åº¦ï¼Œè¶…è¿‡æ­¤é•¿åº¦çš„åºåˆ—å°†è¢«æˆªæ–­')
    parser.add_argument('--analyze_only', action='store_true', help='ä»…åˆ†ææ•°æ®é›†ï¼Œä¸è¿›è¡Œè®­ç»ƒ')
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    config_parser = ConfigParser(args.config)
    
    # è·å–å®éªŒé…ç½®
    exp_config = config_parser.get_experiment_config()
    
    # åˆå§‹åŒ–å®éªŒ
    My_experiment = PEFTExperiment(
        model_name=exp_config['model_name'],
        dataset_name=exp_config['dataset_name'],
        task_type=exp_config['task_type'],
        config=config_parser.config
    )
    
    if args.analyze_only:
        # åªåˆ†ææ•°æ®é›†ä¸è®­ç»ƒ
        print("ä»…åˆ†ææ•°æ®é›†...")
        
        # è®°å½•å¼€å§‹æ—¶çš„å†…å­˜
        if torch.cuda.is_available():
            before_mem = torch.cuda.memory_allocated() / (1024 * 1024)
            print(f"æ•°æ®åˆ†æå‰å†…å­˜ä½¿ç”¨: {before_mem:.2f} MB")
            
        dataset = My_experiment.prepare_data()
        
        # è®°å½•å®Œæˆåçš„å†…å­˜
        if torch.cuda.is_available():
            after_mem = torch.cuda.memory_allocated() / (1024 * 1024)
            print(f"æ•°æ®åˆ†æåå†…å­˜ä½¿ç”¨: {after_mem:.2f} MB")
            print(f"æ•°æ®åˆ†æå†…å­˜å¢åŠ : {after_mem - before_mem:.2f} MB")
            
            # è®°å½•å³°å€¼å†…å­˜
            max_mem = torch.cuda.max_memory_allocated() / (1024 * 1024)
            print(f"æ•°æ®åˆ†æå³°å€¼å†…å­˜ä½¿ç”¨: {max_mem:.2f} MB")
        exit(0)
    
    if args.mode == 'train':
        # è·å–PEFTå’Œè®­ç»ƒé…ç½®
        peft_config = config_parser.get_peft_config()#.yamlæ–‡ä»¶ä¸­çš„pefté…ç½®
        training_config = config_parser.get_training_config()#.yamlæ–‡ä»¶ä¸­çš„trainingé…ç½®
        
        # æ‰§è¡Œå•æ¬¡è®­ç»ƒ
        results = My_experiment.train_with_peft(
            peft_method=peft_config['method'],
            peft_params=peft_config['params'],
            training_params=training_config
        )
        print(f"è®­ç»ƒå®Œæˆâœ…")
        
    else:  # tuneæ¨¡å¼
        # è·å–è¶…å‚æ•°ä¼˜åŒ–å™¨é…ç½®
        tuner_config = config_parser.get_tuner_config()
        
        # è·å–æœç´¢ç©ºé—´
        search_space = {
            'peft': config_parser.get_peft_search_space(),
            'training': config_parser.get_training_search_space()
        }
        
        # æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–
        tuner = HyperparameterTuner(
            experiment=My_experiment,
            direction=tuner_config['direction'],
            study_name=tuner_config['study_name'],
            search_space=search_space
        )
        tuner.run(n_trials=tuner_config['n_trials'])
        tuner.summarize_results()